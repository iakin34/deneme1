package main

import (
        "encoding/json"
        "fmt"
        "io"
        "log"
        "net/http"
        "net/url"
        "os"
        "regexp"
        "sync"
        "time"

        "golang.org/x/net/proxy"
)

type UpbitAPIResponse struct {
        Success bool       `json:"success"`
        Data    UpbitData2 `json:"data"`
}

type UpbitData2 struct {
        Notices []Announcement `json:"notices"`
}

type Announcement struct {
        ID    int    `json:"id"`
        Title string `json:"title"`
}

type ListingEntry struct {
        Symbol     string `json:"symbol"`
        Timestamp  string `json:"timestamp"`
        DetectedAt string `json:"detected_at"`
}

type ListingsData struct {
        Listings []ListingEntry `json:"listings"`
}

// Type aliases for compatibility with telegram_bot.go
type CoinDetection = ListingEntry
type UpbitDetection = ListingEntry
type UpbitData = ListingsData

type UpbitMonitor struct {
        apiURL          string
        proxies         []string
        tickerRegex     *regexp.Regexp
        cachedTickers   map[string]bool
        cachedETag      string
        proxyIndex      int
        mu              sync.Mutex
        jsonFile        string
        onNewListing    func(symbol string) // Callback for new listings
}

func NewUpbitMonitor(onNewListing func(string)) *UpbitMonitor {
        var proxies []string
        
        for i := 1; i <= 11; i++ {
                proxyEnv := os.Getenv(fmt.Sprintf("UPBIT_PROXY_%d", i))
                if proxyEnv != "" {
                        proxies = append(proxies, proxyEnv)
                }
        }

        if len(proxies) == 0 {
                proxies = []string{
                        "socks5://doproxy1:DigitalOcean55@143.198.221.194:1080",
                        "socks5://doproxy2:DigitalOcean55@159.223.68.49:1080",
                        "socks5://doproxy3:DigitalOcean55@104.248.147.230:1080",
                }
                log.Printf("‚ö†Ô∏è UPBIT_PROXY environment variables not set, using %d default proxies", len(proxies))
        } else {
                log.Printf("‚úÖ Loaded %d proxies from environment variables", len(proxies))
        }

        return &UpbitMonitor{
                apiURL:        "https://api-manager.upbit.com/api/v1/announcements?os=web&page=1&per_page=20&category=overall",
                proxies:       proxies,
                tickerRegex:   regexp.MustCompile(`\(([A-Z]{2,6})\)`), // Only 2-6 uppercase letters (valid tickers)
                cachedTickers: make(map[string]bool),
                proxyIndex:    0,
                jsonFile:      "upbit_new.json",
                onNewListing:  onNewListing,
        }
}

func (um *UpbitMonitor) createProxyClient(proxyURL string) (*http.Client, error) {
        parsedURL, err := url.Parse(proxyURL)
        if err != nil {
                return nil, fmt.Errorf("proxy URL'si ayrƒ±≈ütƒ±rƒ±lamadƒ±: %w", err)
        }

        dialer, err := proxy.FromURL(parsedURL, proxy.Direct)
        if err != nil {
                return nil, fmt.Errorf("proxy dialer olu≈üturulamadƒ±: %w", err)
        }

        transport := &http.Transport{
                Dial: dialer.Dial,
        }

        client := &http.Client{
                Transport: transport,
                Timeout:   10 * time.Second,
        }

        return client, nil
}

func (um *UpbitMonitor) loadExistingData() error {
        if _, err := os.Stat(um.jsonFile); os.IsNotExist(err) {
                return nil
        }

        data, err := os.ReadFile(um.jsonFile)
        if err != nil {
                return fmt.Errorf("error reading JSON file: %v", err)
        }

        var listingsData ListingsData
        if err := json.Unmarshal(data, &listingsData); err != nil {
                return fmt.Errorf("error parsing JSON: %v", err)
        }

        for _, entry := range listingsData.Listings {
                um.cachedTickers[entry.Symbol] = true
        }

        log.Printf("Loaded %d existing symbols from %s", len(um.cachedTickers), um.jsonFile)
        return nil
}

func (um *UpbitMonitor) saveToJSON(symbol string) error {
        var data ListingsData
        if _, err := os.Stat(um.jsonFile); err == nil {
                fileData, err := os.ReadFile(um.jsonFile)
                if err != nil {
                        return fmt.Errorf("error reading existing JSON: %v", err)
                }
                json.Unmarshal(fileData, &data)
        }

        // DUPLICATE CHECK: If symbol already exists in file, skip saving
        for _, entry := range data.Listings {
                if entry.Symbol == symbol {
                        log.Printf("‚ö†Ô∏è DUPLICATE PREVENTED: %s already exists in %s, skipping save", symbol, um.jsonFile)
                        return nil // Not an error, just skip
                }
        }

        now := time.Now()
        newEntry := ListingEntry{
                Symbol:     symbol,
                Timestamp:  now.Format(time.RFC3339),
                DetectedAt: now.UTC().Format("2006-01-02 15:04:05 UTC"),
        }

        data.Listings = append([]ListingEntry{newEntry}, data.Listings...)

        tempFile := um.jsonFile + ".tmp"
        jsonData, err := json.MarshalIndent(data, "", "  ")
        if err != nil {
                return fmt.Errorf("error marshaling JSON: %v", err)
        }

        if err := os.WriteFile(tempFile, jsonData, 0644); err != nil {
                return fmt.Errorf("error writing temp file: %v", err)
        }

        if err := os.Rename(tempFile, um.jsonFile); err != nil {
                os.Remove(tempFile)
                return fmt.Errorf("error renaming temp file: %v", err)
        }

        log.Printf("‚úÖ Successfully saved NEW listing %s to %s", symbol, um.jsonFile)
        return nil
}

// normalizeText: Unicode normalization and whitespace cleanup
func normalizeText(text string) string {
        // Remove punctuation and emojis, normalize whitespace
        reg := regexp.MustCompile(`[\p{P}\p{S}\p{Z}]+`)
        normalized := reg.ReplaceAllString(text, " ")
        normalized = regexp.MustCompile(`\s+`).ReplaceAllString(normalized, " ")
        return regexp.MustCompile(`\s+`).ReplaceAllString(normalized, "")
}

// containsAll: Check if text contains all words (order independent)
func containsAll(text string, words []string) bool {
        normalized := normalizeText(text)
        for _, word := range words {
                if !regexp.MustCompile(normalizeText(word)).MatchString(normalized) {
                        return false
                }
        }
        return true
}

// containsAny: Check if text contains any word
func containsAny(text string, words []string) bool {
        normalized := normalizeText(text)
        for _, word := range words {
                if regexp.MustCompile(normalizeText(word)).MatchString(normalized) {
                        return true
                }
        }
        return false
}

// isNegativeFiltered: Rule 2 - Negative filtering (highest priority)
func isNegativeFiltered(title string) bool {
        negativeRules := [][]string{
                {"Í±∞ÎûòÏßÄÏõê", "Ï¢ÖÎ£å"},           // trading support ended
                {"ÏÉÅÏû•ÌèêÏßÄ"},                   // delisting
                {"Ïú†Ïùò", "Ï¢ÖÎ™©", "ÏßÄÏ†ï"},       // caution designation
                {"Ìà¨Ïûê", "Ïú†Ïùò", "Ï¥âÍµ¨"},       // investment caution warning
                {"Ïú†Ïùò", "Ï¥âÍµ¨"},               // caution warning
                {"Ïú†Ïùò", "Ï¢ÖÎ™©", "ÏßÄÏ†ï", "Ìï¥Ï†ú"}, // caution designation removal
        }
        
        for _, rule := range negativeRules {
                if containsAll(title, rule) {
                        log.Printf("üö´ Negative filter: '%s' (contains: %v)", title, rule)
                        return true
                }
        }
        return false
}

// isPositiveFiltered: Rule 3 - Positive filtering
func isPositiveFiltered(title string) bool {
        positiveRules := [][]string{
                {"Ïã†Í∑ú", "Í±∞ÎûòÏßÄÏõê"},     // new trading support
                {"ÎîîÏßÄÌÑ∏", "ÏûêÏÇ∞", "Ï∂îÍ∞Ä"}, // digital asset addition
        }
        
        for _, rule := range positiveRules {
                if containsAll(title, rule) {
                        return true
                }
        }
        return false
}

// isMaintenanceUpdate: Rule 4 - Maintenance/Update filter
func isMaintenanceUpdate(title string) bool {
        updateKeywords := []string{
                "Î≥ÄÍ≤Ω", "Ïó∞Í∏∞", "Ïó∞Ïû•", "Ïû¨Í∞ú", 
                "ÏûÖÏ∂úÍ∏à", "Ïù¥Î≤§Ìä∏", "Ï∂úÍ∏à ÏàòÏàòÎ£å",
        }
        
        if containsAny(title, updateKeywords) {
                log.Printf("üîß Maintenance/Update filter: '%s'", title)
                return true
        }
        return false
}

// extractTickers: Rule 5 - Extract tickers from title
func extractTickers(title string) []string {
        var tickers []string
        tickerMap := make(map[string]bool)
        
        // Find all parentheses content
        parenRegex := regexp.MustCompile(`\(([^)]+)\)`)
        matches := parenRegex.FindAllStringSubmatch(title, -1)
        
        for _, match := range matches {
                content := match[1]
                
                // Skip if contains "ÎßàÏºì" (market indicator)
                if regexp.MustCompile(`ÎßàÏºì`).MatchString(content) {
                        continue
                }
                
                // Split by comma, trim, uppercase
                parts := regexp.MustCompile(`[,\s]+`).Split(content, -1)
                for _, part := range parts {
                        part = regexp.MustCompile(`\s+`).ReplaceAllString(part, "")
                        part = regexp.MustCompile(`[^A-Z0-9]`).ReplaceAllString(part, "")
                        
                        // Exclude market symbols
                        if part == "KRW" || part == "BTC" || part == "USDT" {
                                continue
                        }
                        
                        // Validate pattern [A-Z0-9]{1,10}
                        if regexp.MustCompile(`^[A-Z0-9]{1,10}$`).MatchString(part) {
                                if !tickerMap[part] {
                                        tickerMap[part] = true
                                        tickers = append(tickers, part)
                                }
                        }
                }
        }
        
        return tickers
}

func (um *UpbitMonitor) processAnnouncements(body io.Reader) {
        var response UpbitAPIResponse
        if err := json.NewDecoder(body).Decode(&response); err != nil {
                log.Printf("JSON verisi i≈ülenemedi: %v", err)
                return
        }

        newTickers := make(map[string]bool)
        var newTickersList []string

        for _, announcement := range response.Data.Notices {
                title := announcement.Title
                
                // Rule 2: Negative filtering (highest priority - skips everything)
                if isNegativeFiltered(title) {
                        continue
                }
                
                // Rule 3: Positive filtering (must pass)
                if !isPositiveFiltered(title) {
                        continue
                }
                
                // Rule 4: Maintenance/Update filter
                if isMaintenanceUpdate(title) {
                        continue
                }
                
                // Rule 5: Extract tickers
                tickers := extractTickers(title)
                if len(tickers) > 0 {
                        log.Printf("‚úÖ Valid listing detected: '%s' ‚Üí Tickers: %v", title, tickers)
                        for _, ticker := range tickers {
                                newTickers[ticker] = true
                                newTickersList = append(newTickersList, ticker)
                        }
                }
        }

        um.mu.Lock()
        defer um.mu.Unlock()

        var newlyAdded []string
        for ticker := range newTickers {
                if !um.cachedTickers[ticker] {
                        newlyAdded = append(newlyAdded, ticker)
                }
        }

        if len(newlyAdded) > 0 {
                fmt.Printf("\nüî•üî•üî• YENƒ∞ Lƒ∞STELEME TESPƒ∞T EDƒ∞LDƒ∞: %v üî•üî•üî•\n", newlyAdded)
                for _, ticker := range newlyAdded {
                        um.cachedTickers[ticker] = true
                        if err := um.saveToJSON(ticker); err != nil {
                                log.Printf("Error saving ticker %s: %v", ticker, err)
                        }
                        if um.onNewListing != nil {
                                go um.onNewListing(ticker)
                        }
                }
        }

        // MERGE newTickers into cachedTickers (don't replace!)
        for ticker := range newTickers {
                um.cachedTickers[ticker] = true
        }
        
        log.Printf("üìä Cached tickers count: %d, Current API response: %v", len(um.cachedTickers), newTickersList)
}

func (um *UpbitMonitor) startProxyWorker(proxyURL string, proxyIndex int, staggerMs int) {
        // Stagger start times dynamically based on proxy count
        staggerDelay := time.Duration(proxyIndex*staggerMs) * time.Millisecond
        time.Sleep(staggerDelay)

        // Fixed interval: 4s per proxy = 900 req/hour (safe under 1200 Upbit limit)
        interval := 4 * time.Second
        ticker := time.NewTicker(interval)
        defer ticker.Stop()

        log.Printf("üîÑ Proxy worker #%d started (interval: %v, stagger: %v)", proxyIndex+1, interval, staggerDelay)

        client, err := um.createProxyClient(proxyURL)
        if err != nil {
                log.Printf("‚ùå Proxy #%d client creation failed: %v", proxyIndex+1, err)
                return
        }

        for range ticker.C {
                req, err := http.NewRequest("GET", um.apiURL, nil)
                if err != nil {
                        log.Printf("‚ùå Proxy #%d: Request creation failed: %v", proxyIndex+1, err)
                        continue
                }

                um.mu.Lock()
                if um.cachedETag != "" {
                        req.Header.Set("If-None-Match", um.cachedETag)
                }
                um.mu.Unlock()

                resp, err := client.Do(req)
                if err != nil {
                        log.Printf("‚ùå Proxy #%d: API request failed: %v", proxyIndex+1, err)
                        continue
                }

                switch resp.StatusCode {
                case http.StatusOK:
                        log.Printf("üî• Proxy #%d: CHANGE DETECTED! Processing...", proxyIndex+1)
                        newETag := resp.Header.Get("ETag")
                        um.mu.Lock()
                        um.cachedETag = newETag
                        um.mu.Unlock()
                        um.processAnnouncements(resp.Body)
                        resp.Body.Close()

                case http.StatusNotModified:
                        log.Printf("‚úì Proxy #%d: No change (304)", proxyIndex+1)
                        resp.Body.Close()

                default:
                        log.Printf("‚ö†Ô∏è Proxy #%d: Unexpected status %d", proxyIndex+1, resp.StatusCode)
                        resp.Body.Close()
                }
        }
}

func (um *UpbitMonitor) Start() {
        log.Println("üöÄ Upbit Monitor Starting with DYNAMIC PARALLEL PROXY EXECUTION...")
        
        if err := um.loadExistingData(); err != nil {
                log.Printf("‚ö†Ô∏è Warning: %v", err)
        }

        proxyCount := len(um.proxies)
        if proxyCount == 0 {
                log.Fatal("‚ùå No proxies configured! Please add UPBIT_PROXY_* to .env file")
        }

        // DYNAMIC CALCULATION based on proxy count
        proxyInterval := 4.0 // seconds per proxy (900 req/hour - safe under 1200 limit)
        requestsPerHour := 3600 / proxyInterval // 900 req/hour per proxy
        
        // Stagger dynamically: spread 4s interval across all proxies
        staggerMs := int((4000.0 / float64(proxyCount))) // milliseconds
        coverageSeconds := float64(staggerMs) / 1000.0
        checksPerSecond := 1.0 / coverageSeconds
        
        log.Printf("üìä DYNAMIC PROXY CONFIGURATION:")
        log.Printf("   ‚Ä¢ Total Proxies: %d", proxyCount)
        log.Printf("   ‚Ä¢ Rate Limit: %.0f req/hour per proxy (safe under 1200 limit)", requestsPerHour)
        log.Printf("   ‚Ä¢ Interval: %.0fs per proxy", proxyInterval)
        log.Printf("   ‚Ä¢ Stagger: %dms between workers", staggerMs)
        log.Printf("‚ö° PERFORMANCE:")
        log.Printf("   ‚Ä¢ Coverage: %.0fms (%.3fs)", coverageSeconds*1000, coverageSeconds)
        log.Printf("   ‚Ä¢ Speed: ~%.1f checks/second", checksPerSecond)
        log.Printf("   ‚Ä¢ Total capacity: %.0f req/hour", float64(proxyCount)*requestsPerHour)

        // Launch parallel workers for each proxy with dynamic stagger
        for i, proxyURL := range um.proxies {
                go um.startProxyWorker(proxyURL, i, staggerMs)
        }

        // Keep main goroutine alive
        select {}
}
